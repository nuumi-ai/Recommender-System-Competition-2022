{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktxdLosxtgZd",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Light GCN Sample Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Env Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T04:05:08.204448Z",
     "iopub.status.busy": "2022-09-28T04:05:08.204127Z",
     "iopub.status.idle": "2022-09-28T04:05:08.208400Z",
     "shell.execute_reply": "2022-09-28T04:05:08.207456Z",
     "shell.execute_reply.started": "2022-09-28T04:05:08.204422Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install ipywidgets\n",
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.12.0+cu116.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.12.0+cu116.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T04:05:16.755256Z",
     "iopub.status.busy": "2022-09-28T04:05:16.754944Z",
     "iopub.status.idle": "2022-09-28T04:05:19.559673Z",
     "shell.execute_reply": "2022-09-28T04:05:19.558872Z",
     "shell.execute_reply.started": "2022-09-28T04:05:16.755232Z"
    },
    "id": "Y9fonQcxt3do",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzLUutf7uNAS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Check our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T04:05:24.540932Z",
     "iopub.status.busy": "2022-09-28T04:05:24.540440Z",
     "iopub.status.idle": "2022-09-28T04:05:24.551815Z",
     "shell.execute_reply": "2022-09-28T04:05:24.550941Z",
     "shell.execute_reply.started": "2022-09-28T04:05:24.540906Z"
    },
    "id": "J_CDy1cbuF4_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch_geometric.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set device for torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T04:05:28.094312Z",
     "iopub.status.busy": "2022-09-28T04:05:28.093946Z",
     "iopub.status.idle": "2022-09-28T04:05:28.098528Z",
     "shell.execute_reply": "2022-09-28T04:05:28.097844Z",
     "shell.execute_reply.started": "2022-09-28T04:05:28.094287Z"
    },
    "id": "b4pKT5jUt3pz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYnQc9UH07Fg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.1 Read Data\n",
    "\n",
    "To keep the notebook as simple as possible, we only consider three columns: place_index, user_index, and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T04:19:00.774144Z",
     "iopub.status.busy": "2022-09-28T04:19:00.773432Z",
     "iopub.status.idle": "2022-09-28T04:19:03.716543Z",
     "shell.execute_reply": "2022-09-28T04:19:03.715618Z",
     "shell.execute_reply.started": "2022-09-28T04:19:00.774118Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "columns_name = ['place_index', 'user_index', 'rating']\n",
    "review_df = pd.read_csv(\"../competition-data/train.tsv\", sep=\"\\t\")[columns_name].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Number of User and Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_user = len(review_df['user_index'].unique())\n",
    "num_place = len(review_df['place_index'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T04:19:08.987210Z",
     "iopub.status.busy": "2022-09-28T04:19:08.986887Z",
     "iopub.status.idle": "2022-09-28T04:19:09.175583Z",
     "shell.execute_reply": "2022-09-28T04:19:09.174815Z",
     "shell.execute_reply.started": "2022-09-28T04:19:08.987185Z"
    },
    "id": "SWwvL8JOmrT4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# It is possible some users or restaurants in test do not exist in \n",
    "# train after this split.\n",
    "# Will need to retrain the model with combined train+test after picking\n",
    "# the best model structure\n",
    "train, test = train_test_split(review_df.values, test_size=0.1)\n",
    "train_df = pd.DataFrame(train, columns=review_df.columns)\n",
    "test_df = pd.DataFrame(test, columns=review_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Get distribution of different ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights will be used to normalize loss function\n",
    "def get_weights(df):\n",
    "    rating_counts = np.array([len(df[df['rating'] == i]) for i in [1, 2, 3, 4, 5]])\n",
    "    inverse_count = 1 / rating_counts\n",
    "    norm = np.linalg.norm(inverse_count)\n",
    "    normalized_inverse_count = inverse_count / norm\n",
    "\n",
    "    return normalized_inverse_count\n",
    "\n",
    "weights = get_weights(train_df)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['weight'] = train_df['rating'].map(lambda val: weights[int(val)-1])\n",
    "test_df['weight'] = test_df['rating'].map(lambda val: weights[int(val)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data snippet\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNoblY5kxlv_",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.5 Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T04:29:41.367161Z",
     "iopub.status.busy": "2022-09-28T04:29:41.366316Z",
     "iopub.status.idle": "2022-09-28T04:29:41.372542Z",
     "shell.execute_reply": "2022-09-28T04:29:41.371543Z",
     "shell.execute_reply.started": "2022-09-28T04:29:41.367132Z"
    },
    "id": "NQRGy-CJnOkg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data.to_numpy()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index, 0].astype(np.compat.long), \\\n",
    "            self.data[index, 1].astype(np.compat.long), \\\n",
    "            self.data[index, 2:3].astype(np.float32), \\\n",
    "            self.data[index, 3]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjHZg1Eu-MKs",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Graph Construction\n",
    "\n",
    "A graph is defined as a set of nodes and edges. In our case, we can simply treat users and restaurants as nodes in graphs, and the interaction between user and restaurant (i.e. the review users give to restaurants) as edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also refactor `user_index` and `place_index` to node indices. Currently both `user_index` and `place_index` start from 0, so we add `num_user` to all place indices, so that `user_index` and `place_index` are in the same space and don't overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then construct edge indices by connecting every user to one's reviewed restaurants, and every restaurant to its reviewers, or more formally\n",
    "\n",
    "$$\\mathbf{E} = \\bigcup_{(u_i, r_i)}\\{(u_i, r_i), (r_i, u_i)\\}$$\n",
    "\n",
    "You will see in following training section, how this edge indices are used. You are welcome to make edits to graph construction to improve model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T04:29:45.034832Z",
     "iopub.status.busy": "2022-09-28T04:29:45.034193Z",
     "iopub.status.idle": "2022-09-28T04:29:45.088226Z",
     "shell.execute_reply": "2022-09-28T04:29:45.087347Z",
     "shell.execute_reply.started": "2022-09-28T04:29:45.034807Z"
    },
    "id": "O3BkGyV9pkce",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "u_t = torch.LongTensor(train_df.user_index.to_numpy())\n",
    "p_t = torch.LongTensor(train_df.place_index.to_numpy()) + num_user\n",
    "\n",
    "train_edge_index = torch.stack((torch.cat([u_t, p_t]),torch.cat([p_t, u_t]))).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['place_index'] = train_df['place_index'] + num_user\n",
    "test_df['place_index'] = test_df['place_index'] + num_user\n",
    "\n",
    "# assert that there's no index overlapping\n",
    "intersection = set(train_df['place_index'].unique()).intersection(set(train_df['user_index'].unique()))\n",
    "assert len(intersection) == 0\n",
    "\n",
    "intersection = set(test_df['place_index'].unique()).intersection(set(test_df['user_index'].unique()))\n",
    "assert len(intersection) == 0\n",
    "\n",
    "train_dataset = MyDataset(train_df)\n",
    "test_dataset = MyDataset(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ys1P7mtcr54",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Model Architecture\n",
    "\n",
    "First, let's take a look at the graph convolutional layers that will power our recommender system GNN. Then, we can implement a wrapper to stack multiple convolutional layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49WD8SryyUds",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.1 LightGCN Convolutional Layer\n",
    "\n",
    "The LightGCN architecture is governed by the following rules:\n",
    "\n",
    "$$e_{u}^{(k+1)} = \\sum\\limits_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|}\\sqrt{|N_i|}}e^{(k)}_i$$\n",
    "\n",
    "$$e_{i}^{(k+1)} = \\sum\\limits_{u \\in N_i} \\frac{1}{\\sqrt{|N_i|}\\sqrt{|N_u|}}e^{(k)}_u$$\n",
    "In essence, the embedding for each node after a single LightGCN layer is the sum of the synthetic normalized embeddings of it's neighbors before the layer.\n",
    "\n",
    "An example to illustrate how it works is appended below. Check it out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcUsEulPtNNp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we use MessagePassing layer from PyG (PyTorch Geometric), which we installed in the beginning of this notebook. For more information about using this package, check the very nice tutorial on their website: https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html.\n",
    "\n",
    "A MessagePassing layer, as it inherits from pytorch `nn.Module` class, is called with `forward` function, as we will later see. The special feature of graph learning in MessagePassing layer happens in `propagate` function. There are typically three steps happening in `propagate`:\n",
    "\n",
    "1. **message**\n",
    "This function defines what message we want to pass from a node to another. In the following example, we simply pass the node embedding of a user node or a restaurant node to its neighbors, but you can add more information to it. For example, a user node can also let its' neighbors know what the average rating a user gives.\n",
    "\n",
    "2. **aggregate**\n",
    "When the node receives messages from its neighbors (sent by `message()` function), there are different ways to aggregate the messages. For example, we can simply add all the messages together (assume that the messages are already normalized). Or we can calculate the average, or pick element-wise max values, etc. This is like pooling layers in a traditional Convolutional Neural Network.\n",
    "\n",
    "3. **update**\n",
    "After aggregating the messages collected from neighbors, we will need to update the embedding of current node. By default we update the nodes with aggregation results. But there's always space for creativity.\n",
    "\n",
    "You may override each of the three methods above, to define your own behaviors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following example, we defined our own `message` function. We multiply the current node embedding with the normalization coefficient to get the message we want the node to send to its' neighbors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can specify the type of aggregation our `MessagePassing` layer should use by passing in an `aggr=` argument in the layer initialization. Here we use `add` to specify summation aggregation of messages.\n",
    "\n",
    "Note that we could have manually defined our aggregation function by defining a function explicitly in the class:\n",
    "```\n",
    "def aggregate(self, x, messages, index):\n",
    "  return torch_scatter.scatter(messages, index, self.node_dim, reduce=\"sum\")\n",
    "```\n",
    "The `torch_scatter.scatter` function enables us to aggregate messages being sent to the same node. The `reduce=` argument specifies how to aggregate, while `index` has the same length as the `messages` tensor and maps from message to destination node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T04:29:49.256735Z",
     "iopub.status.busy": "2022-09-28T04:29:49.256047Z",
     "iopub.status.idle": "2022-09-28T04:29:49.262307Z",
     "shell.execute_reply": "2022-09-28T04:29:49.261567Z",
     "shell.execute_reply.started": "2022-09-28T04:29:49.256707Z"
    },
    "id": "-aTMoHisNIh_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LightGCNConv(MessagePassing):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(aggr='add')\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Compute normalization\n",
    "        from_, to_ = edge_index\n",
    "        deg = degree(to_, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[from_] * deg_inv_sqrt[to_]\n",
    "        # Start propagating messages (no update after aggregation)\n",
    "        return self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1, 1) * x_j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our implementation of the LightGCN convolution by applying it to a small bipartite graph.\n",
    "\n",
    "This sample graph is undirected, and node 0 is connected to nodes 2 and 3 while node 1 is connected to 3 and 4. Imagine that as, node 0 is a user who reviewed restaurants node 2 and node 3. Node 1 is another user who reviewed restaurant node 3 and node 4.\n",
    "\n",
    "The following image shows the graph, and labels the process how embedding of node 0 is updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![GCN sample](https://drive.google.com/uc?export=view&id=13-LiDY5Gftj4UfbT_QVrr419dFaop1MY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize node embeddings as one-hot embeddings\n",
    "test_x = torch.Tensor(np.eye(5))\n",
    "\n",
    "# Construct edges\n",
    "test_edge_index = torch.LongTensor(np.array([\n",
    "  [0, 0, 1, 1, 2, 3, 3, 4],\n",
    "  [2, 3, 3, 4, 0, 0, 1, 1]\n",
    "]))\n",
    "\n",
    "# Check out the result of passing the embeddings through our Graph Convolutional Network\n",
    "LightGCNConv()(test_x, test_edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2tW9FJFqNjn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.2 Recommender System GNN\n",
    "\n",
    "Next we embed the LightGCN layer into a full neural network.\n",
    "\n",
    "In `forward` function, we get the embeddings of the 0-th layer (the only trainable parameters of LightGCN other than `nn`), then use LightGCNConv to calculate the embeddings of the higher layer. Finally, we use the mean of the embeddings of each layer as the final embeddings. We also can observe the fact that the embedding of the node that is not in `edge_index` remains unchanged after `forward`.\n",
    "\n",
    "In `pred` function, we concatenated user embedding and restaurant embedding that we are interested in, and predict the ratings based on the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T04:29:55.128388Z",
     "iopub.status.busy": "2022-09-28T04:29:55.128015Z",
     "iopub.status.idle": "2022-09-28T04:29:55.137444Z",
     "shell.execute_reply": "2022-09-28T04:29:55.136459Z",
     "shell.execute_reply.started": "2022-09-28T04:29:55.128356Z"
    },
    "id": "nT5LTkI8Ml1c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, latent_dim, num_layers, num_users, num_items):\n",
    "        super(LightGCN, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_users + num_items, latent_dim)\n",
    "        self.convs = nn.ModuleList(LightGCNConv() for _ in range(num_layers))\n",
    "        self.init_parameters()\n",
    "        self.nn = nn.Linear(2*latent_dim, 1)\n",
    "\n",
    "    def init_parameters(self):\n",
    "        nn.init.normal_(self.embedding.weight, std=0.1) \n",
    "\n",
    "    def forward(self, edge_index):\n",
    "        emb0 = self.embedding.weight\n",
    "        embs = [emb0]\n",
    "        emb = emb0\n",
    "        for conv in self.convs:\n",
    "            emb = conv(x=emb, edge_index=edge_index)\n",
    "            embs.append(emb)\n",
    "\n",
    "        out = torch.mean(torch.stack(embs, dim=0), dim=0)\n",
    "        return emb0, out\n",
    "    \n",
    "    def pred(self, users, items, embeddings):\n",
    "        user_emb = embeddings[users]\n",
    "        item_emb = embeddings[items]\n",
    "        x = torch.cat((user_emb,item_emb), 1)\n",
    "        x = self.nn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qOC3fF9m6cH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Train and evaluate models\n",
    "\n",
    "Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T04:29:59.336359Z",
     "iopub.status.busy": "2022-09-28T04:29:59.335998Z",
     "iopub.status.idle": "2022-09-28T04:29:59.340947Z",
     "shell.execute_reply": "2022-09-28T04:29:59.340144Z",
     "shell.execute_reply.started": "2022-09-28T04:29:59.336319Z"
    },
    "id": "MZtgfxxIm5nL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "n_layers = 3 \n",
    "\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 100\n",
    "DECAY = 0.0001\n",
    "LR = 0.005 \n",
    "K = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T04:30:01.615743Z",
     "iopub.status.busy": "2022-09-28T04:30:01.615380Z",
     "iopub.status.idle": "2022-09-28T04:30:01.696745Z",
     "shell.execute_reply": "2022-09-28T04:30:01.695686Z",
     "shell.execute_reply.started": "2022-09-28T04:30:01.615718Z"
    }
   },
   "outputs": [],
   "source": [
    "lightgcn = LightGCN(\n",
    "    latent_dim=latent_dim,\n",
    "    num_layers=n_layers,\n",
    "    num_users=num_user,\n",
    "    num_items=num_place,\n",
    ")\n",
    "lightgcn = lightgcn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T04:32:32.252808Z",
     "iopub.status.busy": "2022-09-28T04:32:32.252472Z",
     "iopub.status.idle": "2022-09-28T04:32:32.259687Z",
     "shell.execute_reply": "2022-09-28T04:32:32.258563Z",
     "shell.execute_reply.started": "2022-09-28T04:32:32.252782Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_testset_loss(model, testset, loss_fn, embeddings):\n",
    "    loss_list = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for items, users, ratings, weights in DataLoader(testset, batch_size=BATCH_SIZE):\n",
    "            users, items, ratings, weights = users.to(device), items.to(device), ratings.to(device), weights.to(device)\n",
    "            pred = model.pred(users, items, embeddings)\n",
    "            loss = loss_fn(pred, ratings, weights)\n",
    "            \n",
    "            loss_list.append(loss.item())\n",
    "            \n",
    "    return sum(loss_list) / len(loss_list)\n",
    "\n",
    "\n",
    "def train(model, optimizer, train_dataset, test_dataset, n_users, n_restaurants, train_edge_index, loss_fn):\n",
    "    loss_list_epoch = []\n",
    "    valid_loss_list_epoch = []\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "    min_valid_loss = None\n",
    "    min_loss_model = None\n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        n_batch = int(len(train_dataset)/BATCH_SIZE)\n",
    "        loss_list = []\n",
    "        model.train()\n",
    "        for items, users, ratings, weights in tqdm(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            users, items, ratings, weights = users.to(device), items.to(device), ratings.to(device), weights.to(device)\n",
    "            _, embeddings = model(train_edge_index)\n",
    "            pred = model.pred(users, items, embeddings)\n",
    "            loss = loss_fn(pred, ratings, weights)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_list.append(loss.item())\n",
    "            \n",
    "        # evaluate on validation data\n",
    "        valid_loss = get_testset_loss(model, test_dataset, loss_fn, embeddings)\n",
    "        if min_valid_loss is None or valid_loss < min_valid_loss:\n",
    "            min_valid_loss = valid_loss\n",
    "            min_loss_model = torch.save(model.state_dict(), f\"epoch_{epoch}.ckpt\")\n",
    "            \n",
    "        valid_loss_list_epoch.append(round(valid_loss, 4))\n",
    "        loss_list_epoch.append(round(np.mean(loss_list),4))\n",
    "\n",
    "    return loss_list_epoch, valid_loss_list_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4xJSiBiznki",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Set Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T04:34:12.752383Z",
     "iopub.status.busy": "2022-09-28T04:34:12.752022Z",
     "iopub.status.idle": "2022-09-28T04:34:12.757327Z",
     "shell.execute_reply": "2022-09-28T04:34:12.756348Z",
     "shell.execute_reply.started": "2022-09-28T04:34:12.752357Z"
    },
    "id": "eKBv9eXongux",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate weights of different labels and define weighted MSE loss\n",
    "def weighted_MSE(preds, targets, weights):\n",
    "    return (weights * (preds - targets) ** 2).mean()\n",
    "\n",
    "loss_function = weighted_MSE\n",
    "optimizer = torch.optim.Adam(lightgcn.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T04:34:15.782594Z",
     "iopub.status.busy": "2022-09-28T04:34:15.782236Z",
     "iopub.status.idle": "2022-09-28T04:34:52.217021Z",
     "shell.execute_reply": "2022-09-28T04:34:52.214527Z",
     "shell.execute_reply.started": "2022-09-28T04:34:15.782569Z"
    },
    "id": "iXfsuJlcy3FT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss_history, valid_loss_history = train(lightgcn, optimizer, train_dataset, test_dataset, num_user, num_place, train_edge_index, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T22:39:49.754650Z",
     "iopub.status.busy": "2022-09-27T22:39:49.753740Z",
     "iopub.status.idle": "2022-09-27T22:39:49.963771Z",
     "shell.execute_reply": "2022-09-27T22:39:49.962504Z",
     "shell.execute_reply.started": "2022-09-27T22:39:49.754650Z"
    },
    "id": "Z5P2Zf6yT4Uu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epoch_list = [(i+1) for i in range(EPOCHS)]\n",
    "\n",
    "plt.plot(epoch_list, loss_history, label='Training Loss')\n",
    "plt.plot(epoch_list, valid_loss_history, label='Validation Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare for submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have already saved the best model checkpoint above, we now only need to refactor the current notebook into a runnable python script, and generate a .tsv file containing prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data.to_numpy()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index, 0].astype(np.compat.long), \\\n",
    "            self.data[index, 1].astype(np.compat.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_test_data = pd.read_csv(\"../competition-data/test_leaderboard-input.tsv\", sep='\\t')\n",
    "blind_test_data = blind_test_data[['user_index', 'place_index']] # keep only consummable columns\n",
    "blind_test_data['place_index'] += num_user\n",
    "blind_test_dataset = TestDataset(blind_test_data)\n",
    "\n",
    "# All nodes and indices in blind test have already appeared in training data, \n",
    "# so we can re-use the same edge-index\n",
    "model = LightGCN(\n",
    "    latent_dim=latent_dim,\n",
    "    num_layers=n_layers,\n",
    "    num_users=num_user,\n",
    "    num_items=num_place,\n",
    ")\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('./epoch_1.ckpt'))  # replace the checkpoint file with the best candidate\n",
    "_, embeddings = model(train_edge_index)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for items, users in DataLoader(blind_test_dataset, batch_size=BATCH_SIZE):\n",
    "        users, items = users.to(device), items.to(device)\n",
    "        pred = model.pred(users, items, embeddings)\n",
    "        predictions += list(pred.cpu())\n",
    "        \n",
    "predictions = [pred.item() for pred in predictions]\n",
    "blind_test_data['prediction'] = predictions\n",
    "\n",
    "blind_test_data[['prediction']].to_csv('predictions.csv', index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Wrap-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is it!\n",
    "To submit your predictions, remember to refactor the python notebook to a python scipt, that can be run with command `python3 model.py -m model.ckpt -i test_hidden.tsv -o predictions.tsv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this notebook, there are severl improvements you can make:\n",
    "1. Can we integrate more information about the user/restaurant in their embeddings? Such as the average ratings of restaurants, etc.\n",
    "2. Deal with overfitting by adding regularization, drop-out layers, etc.\n",
    "3. Modify data sampling strategy. Currently we are sampling batches of size 1000 randomly from the graph, which means 1000 edges are sample randomly. These edges "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CS 224W Project.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "recommender-py38",
   "language": "python",
   "name": "recommender-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
